<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link rel="apple-touch-icon" href="static/images/apple-touch-icon.png">
  <link rel="manifest" href="static/images/site.webmanifest">
  <title>Data Augmentation for Dog Breed Identification - MLOwl.ca</title>
  <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@400;600;700&display=swap" rel="stylesheet" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" />
  <style>
    :root {
      --main-color: #0077cc;
      --font-body: 'Poppins', sans-serif;
      --max-width: 800px;
    }
    body {
      font-family: var(--font-body);
      margin: 0;
      padding: 0;
      background-color: #f5f7fa;
      color: #222;
    }
    .container {
      max-width: var(--max-width);
      margin: 0 auto;
      padding: 2rem 1rem;
    }
    header {
      margin-bottom: 2rem;
    }
    .featured-image {
      margin-bottom: 1.5rem;
      text-align: center;
    }
    .featured-image img {
      width: 100%;
      height: auto;
      border-radius: 8px;
      margin-bottom: 0.3rem;
    }
    .image-credit {
      font-size: 0.85rem;
      color: #666;
      margin-top: 0;
    }
    h1 {
      font-size: 2.25rem;
      font-weight: 700;
      margin-bottom: 0.5rem;
    }
    .byline {
      color: #666;
      font-size: 0.95rem;
      margin-bottom: 2rem;
    }
    p {
      font-size: 1rem;
      line-height: 1.75;
      margin-bottom: 1.5rem;
    }
    a {
      color: var(--main-color);
      text-decoration: none;
      font-weight: 600;
      border-bottom: 2px solid transparent;
      transition: border-color 0.3s;
    }
    a:hover {
      border-color: var(--main-color);
    }
    footer {
      margin-top: 3rem;
      font-size: 0.95rem;
    }
    @media (max-width: 600px) {
      h1 {
        font-size: 1.75rem;
      }
      .container {
        padding: 1.5rem 1rem;
      }
    }

    /* Inline code styling to match Prism */

    code:not([class]) {
      background-color: #f5f2f0; /* Prism's default bg */
      color: #c7254e; /* Slightly different text color */
      padding: 0.2em 0.4em;
      border-radius: 4px;
    }
  </style>
</head>
<body>
  <div class="container">
    <header>
      <div class="featured-image">
        <img src="static/images/dog_breed_augmentation_blog.jpg" alt="Dog Breed Identification Project Data Augmentation" />
        <div class="image-credit">Image by Martin Bijloos, assembled using a subset of ImageNet's open-source datasets on Kaggle</div>
      </div>
      <h1>Data Augmentation in My Dog Breed Identification Project</h1>
      <p class="byline">By Martin Bijloos, MLOwl.ca | August 13, 2025</p>
    </header>
    <main>
      <h2>üì∏ Why I Needed Data Augmentation</h2>
      <p>When working on my deep learning model for dog breed identification, I noticed a noticeable imbalance in the dataset. Furthermore, most breeds had less than the 100 images recommended by Google for machine learning models to learn patterns effectively. Without intervention, my model would overfit to the majority classes, struggling to recognize minority breeds.</p>
      <p>That‚Äôs when I turned to <strong>data augmentation</strong>‚Äîa technique to artificially increase dataset size and diversity by applying transformations to existing images.</p>

      <h2>üõ†Ô∏è My Data Augmentation Approach</h2>
      <p>I added <code>tensorflow.keras.Sequential</code> to my <code>tf.data</code> pipeline for better performance. The transformations included:</p>
      <ul>
        <li>Random horizontal flips</li>
        <li>Random rotations (up to 10%)</li>
        <li>Random zoom adjustments (up to 10%)</li>
        <li>Random contrast adjustments (up to 10%)</li>
      </ul>

      <h3>Example Code Snippet to call keras sequential layers for augmentation:</h3>
      <pre><code class="language-python">from tensorflow.keras import layers

# Create data augmentation block
data_augmentation = tf.keras.Sequential([
    layers.RandomFlip('horizontal'),
    layers.RandomRotation(0.1),
    layers.RandomZoom(0.1),
    layers.RandomContrast(0.1),
])

def augment_data(image, label):
    image = data_augmentation(image, training = True)
    return image, label
      </code></pre>

      <h3>Example Code Snippet of my data pipeline:</h3>
      <pre><code class="language-python"># Define the batch size
BATCH_SIZE = 32

# Create a function to turn data into batches
def create_data_batches(X, y = None, batch_size = BATCH_SIZE, valid_data = False, test_data = False, augmentation = False):
    """
    Creates batches of data out of image (X) and label (y) pairs.
    Shuffles the data if it's training data but doesn't shuffle if it's validation data.
    Also accepts test data as input (no labels).
    """
    # If the data is a test dataset, we most likely don't have labels
    if test_data:
        print('Creating test data batches...')
        data = tf.data.Dataset.from_tensor_slices((tf.constant(X))) # only filepaths and names (no labels)
        data_batch = data.map(process_image).batch(BATCH_SIZE)
        return data_batch

    # If the data is a valid dataset, we don't need to shuffle it
    elif valid_data:
        print('Creating validation data batches...')
        data = tf.data.Dataset.from_tensor_slices((tf.constant(X), # filepaths and names
                                                   tf.constant(y))) # labels
        data_batch = data.map(get_image_label).batch(BATCH_SIZE)
        return data_batch

    else:
        print('Creating training data batches...')
        # Turn filepaths with names and labels into Tensors
        data = tf.data.Dataset.from_tensor_slices((tf.constant(X),
                                                   tf.constant(y)))
        # Shuffling pathnames, plus filenames and labels before mapping the image processor function, is faster than shuffling the images
        data = data.shuffle(buffer_size = len(X))

        # Create (image, label) tuples (this also turns the image path with name into a preprocessed image)
        data = data.map(get_image_label) # , num_parallel_calls = tf.data.AUTOTUNE) # to optimize GPU usage, but crashes the Kernel

        # Apply augmentation
        if augmentation:
            data = data.map(augment_data) #, num_parallel_calls = tf.data.AUTOTUNE) # to optimize GPU usage, but crashes the Kernel

        # Turn the training data (with augmentation) into batches
        data_batch = data.batch(BATCH_SIZE).cache().prefetch(buffer_size = tf.data.AUTOTUNE) # added cache and prefetch to prevent memory
                                                                                             # overload and crashing

    return data_batch
      </code></pre>

      <h2>üêõ Troubleshooting Along the Way</h2>
      <p>At first, I encountered a couple issues:</p>
      <ul>
        <li>‚ö†Ô∏è Kernal crashes when trying to add augmentation to my data pipeline</li>
        <li>‚ö†Ô∏è Slow computation when reducing batch sizes to alleviate data augmentation burden</li>
      </ul>
      <p>To fix these, I maintained batches of 32 while leveraging <code>cache()</code> and <code>prefetch(tf.data.AUTOTUNE)</code> to store processed data for reuse across epochs and to overlap data with model training respectively. This allowed me to make the most of my MacBook Pro M3 GPU, training the model on 10,222 images in ~5.5 minutes!</p>

      <h2>üìà The Results</h2>
      <p>After augmentation, my model became much better at recognizing minority breeds. Validation accuracy improved, and my confusion matrix showed far fewer classification mistakes for rare classes.</p>

      <h2>üí° Key Takeaways</h2>
      <ul>
        <li>Always check your dataset balance before training.</li>
        <li>Augmentation helps prevent overfitting, improves generalization, and boosts pattern recognition of under-represented classes.</li>
        <li>For large datasets, use <code>tf.data</code> to build efficient input pipelines, especially when performing operations like data augmentation, caching, and prefetching.</li>
      </ul>

      <p>If you‚Äôre training a vision model with imbalanced classes, data augmentation can be a game-changer. It was for me‚Äîand now my dog breed identifier is far more accurate and robust.</p>
    </main>
    <footer>
      <a href="index.html">‚Üê Back to Home</a>
    </footer>
  </div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
</body>
</html>
